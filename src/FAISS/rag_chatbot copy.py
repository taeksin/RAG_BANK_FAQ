import os
import json
import streamlit as st
from streamlit_cookies_manager import EncryptedCookieManager
from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv

# í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ì²« ë²ˆì§¸ Streamlit ëª…ë ¹ì–´)
st.set_page_config(page_title="RAG ê¸°ë°˜ ì±—ë´‡", layout="wide")

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API ì„¤ì •
api_key = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = api_key

# Streamlit ê¸°ë³¸ ì„¤ì •
st.title("RAG ê¸°ë°˜ FAQ ì±—ë´‡ ğŸ¤–")

# ì¿ í‚¤ ê´€ë¦¬ ì´ˆê¸°í™”
cookies = EncryptedCookieManager(prefix="faq_chatbot", password="secure-password")
if not cookies.ready():
    st.stop()

# ì„ë² ë”© ëª¨ë¸ ìƒì„±
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

# FAISS ì €ì¥ì†Œ ê²½ë¡œ ì„¤ì •
base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
faiss_path = os.path.join(base_dir, "data/faiss_index")

# ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
vectorstore = FAISS.load_local(faiss_path, embeddings=embedding_model, allow_dangerous_deserialization=True)
retriever = vectorstore.as_retriever(search_type='mmr', search_kwargs={'k': 5, 'fetch_k': 10, 'lambda_mult': 0.9})

# RAG êµ¬ì„± ìš”ì†Œ ì„¤ì •
prompt = hub.pull("fas_rag_platformdata")
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.5)
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "current_question" not in st.session_state:
    st.session_state.current_question = None
if "current_response" not in st.session_state:
    st.session_state.current_response = None
if "loading" not in st.session_state:
    st.session_state.loading = False

# ì¿ í‚¤ì—ì„œ íˆìŠ¤í† ë¦¬ ë¡œë“œ
if "loaded_history" not in st.session_state:
    chat_history = cookies.get("chat_history")
    if chat_history:
        st.session_state.chat_history = json.loads(chat_history)
    st.session_state.loaded_history = True

# íˆìŠ¤í† ë¦¬ í‘œì‹œ
if st.session_state.chat_history:
    for i, entry in enumerate(st.session_state.chat_history):
        with st.expander(f"ì§ˆë¬¸ {i+1}: {entry['ì§ˆë¬¸']}"):
            st.write(f"**ì§ˆë¬¸:** {entry['ì§ˆë¬¸']}")
            st.write(f"**ë‹µë³€:** {entry['ì‘ë‹µ']}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
if user_input and not st.session_state.loading:
    st.session_state.current_question = user_input
    st.session_state.loading = True  # ë¡œë”© ìƒíƒœ ì‹œì‘
    st.session_state.current_response = None

    # í˜„ì¬ ì§ˆë¬¸ì„ íˆìŠ¤í† ë¦¬ì— ì¦‰ì‹œ ì¶”ê°€ (ì‘ë‹µì€ ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸)
    st.session_state.chat_history.append({"ì§ˆë¬¸": user_input, "ì‘ë‹µ": "ì‘ë‹µ ìƒì„± ì¤‘..."})

# ì‘ë‹µ ìƒì„± ë° ìƒíƒœ ì—…ë°ì´íŠ¸
if st.session_state.loading and st.session_state.current_question:
    with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        # RAG ì‘ë‹µ ìƒì„±
        retrieved_documents = retriever.invoke(st.session_state.current_question)
        response = rag_chain.invoke(st.session_state.current_question)

        # í˜„ì¬ ì‘ë‹µê³¼ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        documents_for_history = [
            {
                "ì€í–‰": doc.metadata.get("ì€í–‰", "ì •ë³´ ì—†ìŒ"),
                "1ì°¨ë¶„ë¥˜": doc.metadata.get("1ì°¨ë¶„ë¥˜", "ì •ë³´ ì—†ìŒ"),
                "2ì°¨ë¶„ë¥˜": doc.metadata.get("2ì°¨ë¶„ë¥˜", "ì •ë³´ ì—†ìŒ"),
                "ì§ˆë¬¸": doc.metadata.get("ì§ˆë¬¸", "ì •ë³´ ì—†ìŒ"),
                "ë‹µë³€": doc.metadata.get("ë‹µë³€", "ì •ë³´ ì—†ìŒ"),
            }
            for doc in retrieved_documents
        ]

        # ì‘ë‹µ ì €ì¥
        st.session_state.current_response = {
            "ì§ˆë¬¸": st.session_state.current_question,
            "ì‘ë‹µ": response,
            "ë¬¸ì„œ": documents_for_history,
        }
        st.session_state.chat_history[-1]["ì‘ë‹µ"] = response
        st.session_state.chat_history[-1]["ë¬¸ì„œ"] = documents_for_history

        # ì¿ í‚¤ì— íˆìŠ¤í† ë¦¬ ì €ì¥
        cookies["chat_history"] = json.dumps(st.session_state.chat_history)
        cookies.save()

        # ìƒíƒœ ê°±ì‹ 
        st.session_state.loading = False
        st.session_state.current_question = None

# í˜„ì¬ ì‘ë‹µ ì¶œë ¥
if st.session_state.loading:
    st.subheader("ì±—ë´‡ ì‘ë‹µ:")
    st.write("ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    
    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì„¹ì…˜ ìˆ¨ê¸°ê¸°
    st.subheader("ê²€ìƒ‰ëœ ë¬¸ì„œ:")
    st.write("ì‘ë‹µ ìƒì„± ì¤‘ì—ëŠ” ë¬¸ì„œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
elif st.session_state.current_response:
    st.subheader("ì±—ë´‡ ì‘ë‹µ:")
    
    # ì§ˆë¬¸ê³¼ ì‘ë‹µì„ í•¨ê»˜ í‘œì‹œ
    st.write(f"**ì§ˆë¬¸:** {st.session_state.current_response['ì§ˆë¬¸']}")
    st.write(f"**ì‘ë‹µ:** {st.session_state.current_response['ì‘ë‹µ']}")

    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œë ¥
    st.subheader("ê²€ìƒ‰ëœ ë¬¸ì„œ:")
    with st.expander("ê²€ìƒ‰ëœ ë¬¸ì„œ ë³´ê¸° (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)"):
        for idx, doc in enumerate(st.session_state.current_response["ë¬¸ì„œ"][:5], 1):  # ìµœëŒ€ 5ê°œ ë¬¸ì„œë§Œ ì¶œë ¥
            st.write(f"### ë¬¸ì„œ {idx}:")
            st.write(f"- **ì€í–‰**: {doc['ì€í–‰']}")
            st.write(f"- **1ì°¨ ë¶„ë¥˜**: {doc['1ì°¨ë¶„ë¥˜']}")
            st.write(f"- **2ì°¨ ë¶„ë¥˜**: {doc['2ì°¨ë¶„ë¥˜']}")
            st.write(f"- **ì§ˆë¬¸**: {doc['ì§ˆë¬¸']}")
            st.write(f"- **ë‹µë³€**: {doc['ë‹µë³€']}")

            # ë¬¸ì„œ ê°„ êµ¬ë¶„ì„ 
            if idx < len(st.session_state.current_response["ë¬¸ì„œ"][:5]):
                st.markdown("---")
