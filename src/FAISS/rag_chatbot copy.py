import os
import json
import streamlit as st
from streamlit_cookies_manager import EncryptedCookieManager
from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="RAG ê¸°ë°˜ ì±—ë´‡", layout="wide")

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API ì„¤ì •
api_key = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = api_key

# Streamlit ê¸°ë³¸ ì„¤ì •
st.title("RAG ê¸°ë°˜ FAQ ì±—ë´‡ ğŸ¤–")

# ì¿ í‚¤ ê´€ë¦¬ ì´ˆê¸°í™”
cookies = EncryptedCookieManager(prefix="faq_chatbot", password="secure-password")
if not cookies.ready():
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë° ì¿ í‚¤ì—ì„œ ë°ì´í„° ë¡œë“œ
if "chat_history" not in st.session_state:
    # ì¿ í‚¤ì—ì„œ ë°ì´í„° ë¡œë“œ
    chat_history = cookies.get("chat_history")
    if chat_history:
        st.session_state.chat_history = json.loads(chat_history)
    else:
        st.session_state.chat_history = []  # ì´ˆê¸°í™” ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •

if "current_question" not in st.session_state:
    st.session_state.current_question = None
if "current_response" not in st.session_state:
    st.session_state.current_response = None
if "loading" not in st.session_state:
    st.session_state.loading = False

# íˆìŠ¤í† ë¦¬ ë””ë²„ê¹…: ì¿ í‚¤ì—ì„œ ë¡œë“œëœ ë°ì´í„° í™•ì¸
st.write("ë””ë²„ê¹…: ì¿ í‚¤ì—ì„œ ë¡œë“œëœ íˆìŠ¤í† ë¦¬:", st.session_state.chat_history)

# ì„ë² ë”© ëª¨ë¸ ìƒì„±
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

# FAISS ì €ì¥ì†Œ ê²½ë¡œ ì„¤ì •
base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
faiss_path = os.path.join(base_dir, "data/faiss_index")

# ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
vectorstore = FAISS.load_local(faiss_path, embeddings=embedding_model, allow_dangerous_deserialization=True)
retriever = vectorstore.as_retriever(search_type='mmr', search_kwargs={'k': 5, 'fetch_k': 10, 'lambda_mult': 0.9})

# RAG êµ¬ì„± ìš”ì†Œ ì„¤ì •
prompt = hub.pull("fas_rag_platformdata")
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.5)
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# íˆìŠ¤í† ë¦¬ í‘œì‹œ í•¨ìˆ˜
def display_history(container):
    with container:
        if st.session_state.chat_history:
            st.subheader("íˆìŠ¤í† ë¦¬:")
            for i, entry in enumerate(st.session_state.chat_history):
                with st.expander(f"ì§ˆë¬¸ {i+1}: {entry['ì§ˆë¬¸']}"):
                    st.write(f"**ì§ˆë¬¸:** {entry['ì§ˆë¬¸']}")
                    st.write(f"**ë‹µë³€:** {entry['ì‘ë‹µ']}")

# ì¿ í‚¤ ì €ì¥ ë””ë²„ê¹… ë° ë°ì´í„° ìµœì†Œí™”
def save_chat_history_to_cookies(cookies):
    try:
        # ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        history_data = json.dumps(st.session_state.chat_history)
        
        # í¬ê¸° ì œí•œ í™•ì¸
        if len(history_data) > 4000:  # 4KB ì œí•œ
            st.error("íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ë„ˆë¬´ ì»¤ì„œ ì¿ í‚¤ì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì¿ í‚¤ì— ì €ì¥
            cookies["chat_history"] = history_data
            cookies.save()
    except Exception as e:
        st.error(f"ì¿ í‚¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# UI ì»¨í…Œì´ë„ˆ ìƒì„±
history_container = st.container()

# ì´ˆê¸° íˆìŠ¤í† ë¦¬ í‘œì‹œ
display_history(history_container)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
if user_input:
    # ì…ë ¥ê°’ ìœ íš¨ì„± ê²€ì‚¬
    if not st.session_state.loading:
        st.session_state.current_question = user_input
        st.session_state.loading = True  # ë¡œë”© ìƒíƒœ ì‹œì‘
        st.session_state.current_response = None

        # í˜„ì¬ ì§ˆë¬¸ì„ íˆìŠ¤í† ë¦¬ì— ì¦‰ì‹œ ì¶”ê°€ (ì‘ë‹µì€ ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸)
        st.session_state.chat_history.append({"ì§ˆë¬¸": user_input, "ì‘ë‹µ": "ì‘ë‹µ ìƒì„± ì¤‘..."})
    else:
        st.warning("í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì´ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")



# ê¸°ì¡´ ì½”ë“œì—ì„œ ì¿ í‚¤ ì €ì¥ ë¶€ë¶„ ìˆ˜ì •
if st.session_state.loading and st.session_state.current_question:
    try:
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # RAG ì‘ë‹µ ìƒì„±
            retrieved_documents = retriever.invoke(st.session_state.current_question)
            response = rag_chain.invoke(st.session_state.current_question)

            # í˜„ì¬ ì‘ë‹µê³¼ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            documents_for_history = [
                {
                    "ì€í–‰": doc.metadata.get("ì€í–‰", "ì •ë³´ ì—†ìŒ"),
                    "1ì°¨ë¶„ë¥˜": doc.metadata.get("1ì°¨ë¶„ë¥˜", "ì •ë³´ ì—†ìŒ"),
                    "2ì°¨ë¶„ë¥˜": doc.metadata.get("2ì°¨ë¶„ë¥˜", "ì •ë³´ ì—†ìŒ"),
                }
                for doc in retrieved_documents
            ]

            # ì‘ë‹µ ì €ì¥
            st.session_state.current_response = {
                "ì§ˆë¬¸": st.session_state.current_question,
                "ì‘ë‹µ": response,
                # "ë¬¸ì„œ": documents_for_history,
            }
            st.session_state.chat_history[-1]["ì‘ë‹µ"] = response
            # st.session_state.chat_history[-1]["ë¬¸ì„œ"] = documents_for_history

            # ì¿ í‚¤ì— íˆìŠ¤í† ë¦¬ ì €ì¥ (ë””ë²„ê¹… ì¶”ê°€)
            save_chat_history_to_cookies(cookies)

    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.session_state.chat_history[-1]["ì‘ë‹µ"] = "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    finally:
        # ìƒíƒœ ê°±ì‹ 
        st.session_state.loading = False
        st.session_state.current_question = None

        # ì‘ë‹µ ìƒì„± í›„ íˆìŠ¤í† ë¦¬ ì»¨í…Œì´ë„ˆë¥¼ ìƒˆë¡œ ë Œë”ë§
        history_container.empty()  # ê¸°ì¡´ ë‚´ìš©ì„ ì§€ì›€
        display_history(history_container)  # ìƒˆë¡œ ë Œë”ë§


# í˜„ì¬ ì‘ë‹µ ì¶œë ¥
if st.session_state.loading:
    st.subheader("ì±—ë´‡ ì‘ë‹µ:")
    st.write("ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤...")

elif st.session_state.current_response:
    st.subheader("ì±—ë´‡ ì‘ë‹µ:")
    st.write(f"**ì§ˆë¬¸:** {st.session_state.current_response['ì§ˆë¬¸']}")
    st.write(f"**ì‘ë‹µ:** {st.session_state.current_response['ì‘ë‹µ']}")
